1
00:00:00,500 --> 00:00:04,650
在这个以及接下来的几个视频中

2
00:00:04,650 --> 00:00:09,510
我想

3
00:00:09,510 --> 00:00:12,651
我们将开发一种叫做逻辑回归的算法,

4
00:00:12,651 --> 00:00:16,931
这是当今最流行和最广泛使用的学习算法之一。

5
00:00:19,473 --> 00:00:23,270
是离散的值

6
00:00:23,270 --> 00:00:26,530
我们将学习一种叫做

7
00:00:26,530 --> 00:00:29,390
逻辑回归 (Logistic Regression) 的算法

8
00:00:29,390 --> 00:00:33,110
这是目前最流行

9
00:00:33,110 --> 00:00:35,540
使用最广泛的一种学习算法

10
00:00:35,540 --> 00:00:39,390
下面是一些分类问题的例子

11
00:00:39,390 --> 00:00:44,590
此前 我们谈到的电子邮件

12
00:00:44,590 --> 00:00:46,830
垃圾邮件分类

13
00:00:46,830 --> 00:00:50,840
就是一个分类问题

14
00:00:50,840 --> 00:00:53,960
另一个例子是网上交易的分类问题

15
00:00:55,120 --> 00:00:59,450
比如一个卖东西的网站

16
00:00:59,450 --> 00:01:04,160
如果你想了解

17
00:01:04,160 --> 00:01:09,080
一个实体的交易

18
00:01:10,500 --> 00:01:15,670
是不是欺诈

19
00:01:15,670 --> 00:01:20,020
我们用一个表示的类的另一个名称是正类。

20
00:01:20,020 --> 00:01:23,930
所以零, 我们表示为良性肿瘤, 和一个,

21
00:01:23,930 --> 00:01:27,110
或者是盗用了别的用户的密码

22
00:01:27,110 --> 00:01:31,370
两个类的分配, 垃圾邮件不是垃圾邮件等等。

23
00:01:31,370 --> 00:01:35,120
两类的赋值为正值和负到零,

24
00:01:35,120 --> 00:01:37,290
一个是有点武断和

25
00:01:37,290 --> 00:01:42,220
区别一个肿瘤是恶性的还是良性的

26
00:01:42,220 --> 00:01:46,590
正在传递的东西, 如没有恶性肿瘤。

27
00:01:46,590 --> 00:01:51,460
我们想要预测的变量

28
00:01:51,460 --> 00:01:55,170
是变量 y

29
00:01:55,170 --> 00:01:58,790
我们可以认为

30
00:02:00,150 --> 00:02:03,080
现在, 我们要开始与分类问题与

31
00:02:03,080 --> 00:02:05,510
0 或 1

32
00:02:05,510 --> 00:02:09,320
后来, 我们将谈论多类问题以及在哪里

33
00:02:09,320 --> 00:02:14,250
因此 y 可以采取四值零, 一, 二, 和三。

34
00:02:14,250 --> 00:02:17,720
标记为0的类

35
00:02:17,720 --> 00:02:22,140
但对于接下来的几个视频, 让我们从两个类或二进制

36
00:02:22,140 --> 00:02:25,978
分类问题, 我们会担心本职设置后。

37
00:02:25,978 --> 00:02:30,580
那么, 我们如何开发一种分类算法呢？

38
00:02:30,580 --> 00:02:34,770
下面是一个用于分类任务的培训集的示例, 用于

39
00:02:34,770 --> 00:02:37,410
将肿瘤归类为恶性或良性。

40
00:02:37,410 --> 00:02:44,570
并注意到, 恶性肿瘤只需要两个值, 零或 no, 一个或是。

41
00:02:44,570 --> 00:02:47,520
可能标记一个恶性肿瘤

42
00:02:47,520 --> 00:02:50,309
是应用我们已经知道的算法。

43
00:02:51,410 --> 00:02:53,410
垃圾邮件

44
00:02:53,410 --> 00:02:56,320
或者不是垃圾邮件 等等

45
00:02:56,320 --> 00:02:59,840
将两个类别标记为

46
00:02:59,840 --> 00:03:03,730
正类或负类

47
00:03:03,730 --> 00:03:05,695
0 或 1 是任意的

48
00:03:05,695 --> 00:03:09,100
其实怎样都可以

49
00:03:09,100 --> 00:03:14,650
但是通常

50
00:03:14,650 --> 00:03:19,165
从直觉上来讲

51
00:03:19,165 --> 00:03:23,985
负类总是表达

52
00:03:23,985 --> 00:03:27,235
缺少某样东西的意思

53
00:03:27,235 --> 00:03:29,955
比如缺少恶性肿瘤

54
00:03:29,955 --> 00:03:32,775
而 1 正类 就会表示

55
00:03:32,775 --> 00:03:36,359
存在某样我们寻找的东西

56
00:03:36,359 --> 00:03:39,990
但是哪个是负类

57
00:03:39,990 --> 00:03:43,520
哪个是正类的定义

58
00:03:43,520 --> 00:03:44,710
有时是任意的 它并不太重要

59
00:03:44,710 --> 00:03:50,360
现在 我们要开始

60
00:03:50,360 --> 00:03:54,629
研究只有两类 0 和 1

61
00:03:55,720 --> 00:03:57,620
的分类问题

62
00:03:57,620 --> 00:04:01,630
以后 我们将讨论多类别问题

63
00:04:01,630 --> 00:04:05,420
多类别问题中的变量 y

64
00:04:05,420 --> 00:04:08,120
的取值可以是

65
00:04:08,120 --> 00:04:11,530
0 1 2 和 3 或更多

66
00:04:11,530 --> 00:04:15,263
这就是所谓的多类分类问题

67
00:04:15,263 --> 00:04:18,900
但在接下来的几个视频中

68
00:04:18,900 --> 00:04:21,960
让我们从两类分类问题

69
00:04:21,960 --> 00:04:26,200
或者叫二元分类问题开始

70
00:04:26,200 --> 00:04:28,970
我们以后再关心多类的问题

71
00:04:28,970 --> 00:04:31,010
那我们怎样开发一个分类算法呢？

72
00:04:31,010 --> 00:04:34,930
下面是一个训练集的例子

73
00:04:34,930 --> 00:04:39,620
这个训练集是用来

74
00:04:39,620 --> 00:04:44,210
给一个肿瘤分类为

75
00:04:44,210 --> 00:04:44,820
恶性或者良性的

76
00:04:46,200 --> 00:04:50,730
注意 这个恶性值 (malignancy)

77
00:04:50,730 --> 00:04:54,480
只取两个值

78
00:04:54,480 --> 00:04:56,090
0也就是非(恶性) 和 1 也就是 是(恶性)

79
00:04:57,600 --> 00:05:02,890
所以拿到这个训练集

80
00:05:02,890 --> 00:05:06,350
我们可以做的一个事情是

81
00:05:06,350 --> 00:05:09,750
将一个我们已知的算法

82
00:05:09,750 --> 00:05:12,070
线性回归用于这组数据

83
00:05:14,590 --> 00:05:18,820
尝试用一条直线来拟合数据

84
00:05:18,820 --> 00:05:23,110
所以如果用一条直线

85
00:05:23,110 --> 00:05:28,090
拟合这个训练集

86
00:05:28,090 --> 00:05:31,260
你有可能得到

87
00:05:31,260 --> 00:05:34,300
看起来像这样的假设函数

88
00:05:34,300 --> 00:05:37,050
好了 这是我的假设函数

89
00:05:37,050 --> 00:05:40,260
h(x) 等于 θ 的转置乘以 x

90
00:05:40,260 --> 00:05:45,210
如果你想进行预测

91
00:05:45,210 --> 00:05:50,880
如果你想进行预测

92
00:05:50,880 --> 00:05:55,670
你可以尝试

93
00:05:56,900 --> 00:06:01,120
将分类器的输出阈值设为0.5

94
00:06:01,120 --> 00:06:04,470
这是纵轴上0.5的位置

95
00:06:04,470 --> 00:06:09,870
如果假设输出的值

96
00:06:09,870 --> 00:06:14,760
大于等于 0.5

97
00:06:14,760 --> 00:06:19,940
你就预测 y 值等于 1

98
00:06:19,940 --> 00:06:24,760
如果小于0.5 预测y等于0

99
00:06:24,760 --> 00:06:28,350
让我们看看当我们这样做的时候会发生什么

100
00:06:29,700 --> 00:06:33,830
所以让我们取 0.5

101
00:06:33,830 --> 00:06:36,740
所以 这就是阈值的位置

102
00:06:36,740 --> 00:06:40,630
就这样使用线性回归算法

103
00:06:40,630 --> 00:06:44,250
这个点右边的所有点

104
00:06:44,250 --> 00:06:48,380
我们会将它们

105
00:06:48,380 --> 00:06:52,570
全部预测为正类

106
00:06:53,920 --> 00:06:56,739
因为它们的输出值

107
00:06:56,739 --> 00:07:00,786
在纵轴上

108
00:07:00,786 --> 00:07:05,661
都是大于0.5的

109
00:07:09,135 --> 00:07:13,795
在这一点左侧

110
00:07:13,795 --> 00:07:17,044
的所有点

111
00:07:17,044 --> 00:07:21,635
我们会预测它们全部为负

112
00:07:21,635 --> 00:07:25,114
在这个特定的例子中

113
00:07:26,250 --> 00:07:29,260
看起来好像线性回归所做的

114
00:07:29,260 --> 00:07:33,370
实际上是合理的

115
00:07:33,370 --> 00:07:38,230
尽管我们感兴趣的是

116
00:07:38,230 --> 00:07:42,150
一个分类问题

117
00:07:42,150 --> 00:07:44,720
现在我们把问题稍微改一下

118
00:07:44,720 --> 00:07:49,210
让我来延长一下横轴

119
00:07:49,210 --> 00:07:54,542
让我来延长一下横轴

120
00:07:54,542 --> 00:07:56,610
假如说新增一个训练样本

121
00:07:56,610 --> 00:08:01,000
在很远的右边那里

122
00:08:01,000 --> 00:08:03,640
注意 这个额外的训练样本

123
00:08:03,640 --> 00:08:04,500
这里这个

124
00:08:04,500 --> 00:08:08,080
它实际上并没有改变什么 对不对 ?