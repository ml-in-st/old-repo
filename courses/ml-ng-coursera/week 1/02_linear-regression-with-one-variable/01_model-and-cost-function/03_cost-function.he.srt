1
00:00:00,620 --> 00:00:03,800
בסרטון הזה נגדיר משהו שנקרא פונקצית עלות

2
00:00:03,800 --> 00:00:07,480
היא תאפשר לנו להחליט איך להתאים את הקו הישר הטוב ביותר לנתונים שלנו.

3
00:00:10,310 --> 00:00:13,820
ברגרסיה ליניארית, יש לנו סט אימון כמו שהראיתי כזכור.

4
00:00:13,820 --> 00:00:18,870
האות m מייצגת את מספר הדוגמאות בסט האימון, אז אולי m = 47.

5
00:00:18,870 --> 00:00:20,989
והצורה של ההיפותזה שלנו,

6
00:00:22,210 --> 00:00:25,360
שבה אנו משתמשים כדי לבצע תחזיות היא הפונקציה הליניארית הזו.

7
00:00:26,430 --> 00:00:31,240
עוד קצת מינוחים, θ0 וθ1

8
00:00:31,240 --> 00:00:37,260
הללו , הם מה שאני מכנה הפרמטרים של המודל.

9
00:00:37,260 --> 00:00:42,560
ומה שאנחנו הולכים לעשות בסרט הזה הוא לדבר על

10
00:00:42,560 --> 00:00:47,550
איך בוחרים את הערכים של שני הפרמטרים האלה, θ0 וθ1.

11
00:00:47,550 --> 00:00:51,100
עם ערכים שונים של הפרמטרים θ0 וθ1

12
00:00:51,100 --> 00:00:55,250
אנחנו נקבל השערות שונות, פונקציות השערה שונות.

13
00:00:55,250 --> 00:00:58,170
אני יודע שחלק מכם כנראה כבר מכירים

14
00:00:58,170 --> 00:01:02,110
את מה שאני עומד לעשות בשקופית הזו, אבל רק לחזרה, הנה כמה דוגמאות.

15
00:01:02,110 --> 00:01:05,990
אם θ0 הוא 1.5 וθ1 הוא 0,

16
00:01:05,990 --> 00:01:08,870
אז פונקצית ההשערה נראית ככה.

17
00:01:10,070 --> 00:01:17,610
כי פונקצית ההשערה היא h של x שווה 1.5 פלוס 0

18
00:01:17,610 --> 00:01:22,533
כפול x שהיא הפונקציה הקבועה הזו שהוא קו ישר ב-1.5.

19
00:01:22,533 --> 00:01:26,600
אם θ0 = 0, θ1 = 0.5, אז ההשערה תיראה ככה,

20
00:01:26,600 --> 00:01:31,420
היא צריכה לעבור דרך הנקודה (2,1).

21
00:01:31,420 --> 00:01:34,850
אז עכשיו יש באמת (h(x

22
00:01:34,850 --> 00:01:40,150
או בעצם hθ של x, אבל אני לפעמים משמיט את הθ לשם קיצור.

23
00:01:40,150 --> 00:01:45,570
אז (h(x שווה 0.5 כפול x, שנראה ככה.

24
00:01:45,570 --> 00:01:49,830
והדוגמה השלישית, אם θ0 שווה ל1, θ1 שווה 0.5,

25
00:01:49,830 --> 00:01:53,280
אז יש לנו השערה שנראית ככה,

26
00:01:53,280 --> 00:01:59,670
בואו נראה, היא צריכה לעבור דרך הנקודה שתיים-שתיים.

27
00:01:59,670 --> 00:02:04,640
כך, אז זו ה-(h(x החדשה שלי, או hθ של x.

28
00:02:04,640 --> 00:02:08,618
לא משנה כך או כך, זוכרים שאמרתי שזה hθ של x, אבל

29
00:02:08,618 --> 00:02:12,095
לפעמים אני פשוט אכתוב את זה בקיצור כ-h של x

30
00:02:13,917 --> 00:02:19,330
ברגרסיה ליניארית, יש לנו סט אימון, אולי כמו זה ששרטטתי כאן.

31
00:02:19,330 --> 00:02:24,880
מה שאנחנו רוצים לעשות, הוא להגדיר ערכי פרמטרים עבור θ0

32
00:02:24,880 --> 00:02:29,960
ו-θ1 כך שהישר שמוגדר על ידיהם תואם

33
00:02:29,960 --> 00:02:33,500
קו ישר שמתאים באיזו שהיא צורה היטב לנתונים, כמו אולי הקו הזה שם.

34
00:02:34,590 --> 00:02:37,190
אז איך אנחנו מוצאים את הערכים

35
00:02:37,190 --> 00:02:40,650
של θ0 וθ1 שיוצרים התאמה טובה לנתונים?

36
00:02:42,540 --> 00:02:46,460
הרעיון הוא שאנחנו בוחרים את הפרמטרים שלנו θ0 וθ1 כך

37
00:02:46,460 --> 00:02:51,190
שh של x, כלומר הערך שאנו צופים לקלט x,

38
00:02:51,190 --> 00:02:55,730
יהיה לפחות קרוב לערך y לגבי

39
00:02:55,730 --> 00:02:59,908
הדוגמאות בסט האימון שלנו.

40
00:02:59,908 --> 00:03:04,000
אז בסדרת האימון שלנו קיבלנו מספר דוגמאות בהן אנו יודעים את x,

41
00:03:04,000 --> 00:03:07,350
הגודל של הבתים ואנחנו יודעים את המחיר בו נמכר הבית בפועל.

42
00:03:07,350 --> 00:03:11,100
אז בואו ננסה לבחור ערכים עבור הפרמטרים כך

43
00:03:11,100 --> 00:03:13,830
שלפחות לגבי סדרת האימון, בהינתן x

44
00:03:13,830 --> 00:03:19,040
בסדרת האימון, נקבל קירוב סביר של ערכי ה-y.

45
00:03:19,040 --> 00:03:20,980
בואו נעשה את זה יותר פורמלי.

46
00:03:20,980 --> 00:03:23,700
אז ברגרסיה, מה שאנחנו נעשה הוא,

47
00:03:23,700 --> 00:03:27,430
אני רוצה לפתור בעיית מזעור - מינימיזציה.

48
00:03:27,430 --> 00:03:34,319
אז אני אכתוב, מזער מעל θ0 וθ1,

49
00:03:34,319 --> 00:03:39,620
ואני רוצה שזה יהיה קטן, נכון?

50
00:03:39,620 --> 00:03:42,960
אני רוצה שההפרש בין (h(x ו-y יהיה קטן ככל האפשר

51
00:03:42,960 --> 00:03:47,770
דבר אחד שאני יכול לעשות הוא לנסות למזער את ריבוע ההפרש

52
00:03:47,770 --> 00:03:51,226
בין התוצאה של פונקצית ההשערה ובין המחיר האמיתי של הבית,

53
00:03:51,226 --> 00:03:54,600
בסדר. אז בואו נגלה כמה פרטים.

54
00:03:54,600 --> 00:03:59,328
אתם זוכרים שהשתמשתי בסימון ((x (i), y (i)

55
00:03:59,328 --> 00:04:02,380
כדי לייצג את דוגמת האימון ה-i.

56
00:04:02,380 --> 00:04:07,480
אז אני רוצה לסכם על סדרת האימון שלי

57
00:04:07,480 --> 00:04:10,666
מ-i=1 עד m

58
00:04:10,666 --> 00:04:16,040
את ריבוע ההפרש בין התחזית,

59
00:04:16,040 --> 00:04:21,261
ההשערה שלי כאשר הקלט הוא גודל של הבית מספר i,

60
00:04:22,560 --> 00:04:25,530
נכון? מינוס המחיר האמיתי של הבית.

61
00:04:25,530 --> 00:04:29,630
המחיר שעבורו נמכר הבית, ואני רוצה למזער את הסכום הזה על סדרת האימון שלי,

62
00:04:29,630 --> 00:04:34,240
הסכום מ-i שווה אחד ועד m של ריבוע ההפרשים האלה.

63
00:04:34,240 --> 00:04:37,160
ריבוע ההפרש בין המחיר החזוי של הבית

64
00:04:37,160 --> 00:04:40,550
ובין המחיר שבו הוא נמכר למעשה.

65
00:04:40,550 --> 00:04:46,950
ורק להזכיר את הסימון, m הוא הגודל של סדרת האימון שלי.

66
00:04:46,950 --> 00:04:50,570
אז m כאן הוא מספר דוגמאות האימון.

67
00:04:50,570 --> 00:04:57,750
הסולמית היא קיצור של המילה מספר, מספר דוגמאות האימון, בסדר?

68
00:04:57,750 --> 00:05:01,270
וכדי לפשט במעט את המתמטיקה,

69
00:05:01,270 --> 00:05:05,950
אני אסתכל דווקא על 1 חלקי m כפול הסכום הזה,

70
00:05:05,950 --> 00:05:09,380
או ננסה למזער את הממוצע, למזער את 1 חלקי 2m.

71
00:05:09,380 --> 00:05:14,450
שמנו כאן 2 במכנה, זה עשוי לפשט

72
00:05:14,450 --> 00:05:18,730
את המתמטיקה, ומזעור של חצי מהממוצע צריך לתת

73
00:05:18,730 --> 00:05:23,130
אותן תוצאות של θ0 וθ1, כמו מזעור של הממוצע השלם.

74
00:05:24,300 --> 00:05:27,640
רק כדי לוודא, המשוואה הזאת ברורה, נכון?

75
00:05:27,640 --> 00:05:31,452
הביטוי הזה כאן, hθ

76
00:05:31,452 --> 00:05:36,560
של x, זה הביטוי הרגיל שלנו, כן?

77
00:05:37,890 --> 00:05:42,668
זה שווה לזה ועוד θ1 של xi.

78
00:05:42,668 --> 00:05:48,050
והסימון זה, מזער מעל θ0 וθ1, פירושו

79
00:05:48,050 --> 00:05:53,140
תמצא לי את הערכים של θ0 וθ1 שגורם לביטוי הזה

80
00:05:53,140 --> 00:05:57,620
לקבל את הערך המינימלי, וביטוי זה תלוי בθ0 וθ1, נכון?

81
00:05:57,620 --> 00:05:58,710
אז הבה נחזור ונסכם

82
00:05:58,710 --> 00:06:03,380
אנחנו מגדירים את הבעיה הזאת כך, מצא את הערכים של θ0 וθ1 כך

83
00:06:03,380 --> 00:06:07,210
שהממוצע, 1 חלקי 2m,

84
00:06:07,210 --> 00:06:11,240
כפול הסכום של ריבועי הסטיות בין התחזיות לגבי סדרת האימון

85
00:06:11,240 --> 00:06:15,250
ובין הערכים בפועל של מחירי הבתים על סדרת האימון יהיה מינימלי.

86
00:06:15,250 --> 00:06:20,709
זו תהיה פונקציית המטרה הכללית של רגרסיה לינארית.

87
00:06:22,080 --> 00:06:27,250
נשכתב את זה קצת יותר על נקי, מה שנעשה זה

88
00:06:27,250 --> 00:06:29,790
הנוהג הוא שאנחנו בדרך כלל מגדירים פונקצית עלות

89
00:06:31,240 --> 00:06:35,930
בדיוק כמו הנוסחה שיש כאן

90
00:06:37,040 --> 00:06:45,289
ומה שאני רוצה לעשות הוא למזער אותה מעל θ0 וθ1

91
00:06:45,289 --> 00:06:51,770
הפונקציה שלי היא (J(θ0, θ1

92
00:06:51,770 --> 00:06:52,430
רק נכתוב את זה...

93
00:06:53,730 --> 00:06:56,540
זוהי פונקצית העלות שלי.

94
00:06:59,380 --> 00:07:04,960
פונקצית העלות הזו נקראת גם פונקציית ריבועי השגיאות או ריבועי הסטיות.

95
00:07:06,850 --> 00:07:11,190
לפעמים היא נקראת פונקצית העלות של השגיאה הריבועית הממוצעת.

96
00:07:11,190 --> 00:07:15,730
הסיבה שאנחנו לוקחים את הריבועים של השגיאות,

97
00:07:15,730 --> 00:07:19,660
מתברר שפונקצית העלות הנקראת ממוצע ריבועי הסטיות היא בחירה סבירה,

98
00:07:19,660 --> 00:07:22,990
שעובדת היטב עבור רוב בעיות הרגרסיה.

99
00:07:22,990 --> 00:07:25,740
ישנן פונקציות עלות אחרות שעובדות די טוב.

100
00:07:25,740 --> 00:07:29,860
אבל פונקצית העלות ריבוע הסטיות היא כנראה הנפוצה ביותר

101
00:07:29,860 --> 00:07:30,935
בבעיות רגרסיה.

102
00:07:30,935 --> 00:07:34,980
בהמשך הקורס הזה נדבר גם על פונקציות עלות אחרות,

103
00:07:34,980 --> 00:07:39,085
אבל הבחירה הזו שעשינו היא די סבירה לנסות

104
00:07:39,085 --> 00:07:41,030
ברוב הבעיות של רגרסיה ליניארית.

105
00:07:42,340 --> 00:07:43,030
בסדר.

106
00:07:43,030 --> 00:07:44,280
אז זוהי פונקצית העלות.

107
00:07:45,340 --> 00:07:50,840
עד עכשיו ראינו רק הגדרה מתמטית של פונקצית העלות הזו.

108
00:07:50,840 --> 00:07:54,310
אם הפונקציה הזו (J(θ0, θ1

109
00:07:54,310 --> 00:07:56,260
אם הפונקציה הזו נראית לך קצת מופשטת,

110
00:07:56,260 --> 00:07:58,885
ועדיין אין לך תחושה טובה של מה היא עושה,

111
00:07:58,885 --> 00:08:03,210
בסרטון או מספר הסרטונים הבאים, אני עומד

112
00:08:03,210 --> 00:08:07,930
לצלול קצת יותר עמוק לתוך מה שעושה פונקצית העלות J ולנסות

113
00:08:07,930 --> 00:08:11,730
לתת לך אינטואיציה טובה יותר על מה היא מחשבת ולמה אנחנו רוצים להשתמש בה.