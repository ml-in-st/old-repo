בסרטון הקודם, נתנו הגדרה מתמטית של פונקצית עלות. בסרטון הזה, בואו נסתכל על כמה דוגמאות, כדי לקבל אינטואיציה לגבי מה עושה פונקצית העלות, ולמה אנחנו רוצים להשתמש בה. לתזכורת, הנה מה שעשינו בפעם שעברה. אנחנו רוצים להתאים קו ישר דרך הנתונים שלנו, אז יצרנו השערה עם הפרמטרים הללו θ₀ ו-θ₁, ועל ידי שימוש בערכים שונים של הפרמטרים אנחנו מקבלים קוים ישרים והתאמות שונות לנתונים, ויש לנו פונקציית עלות, וזו היתה מטרת האופטימיזציה שלנו. אז בסרטון הזה, כדי שנוכל לדמיין את j פונקציית העלות יותר טוב בעיני רוחנו, אני אעבוד עם פונקציה השערה פשוטה, כמו זו המוצגת כאן מימין. אני אשתמש בהשערה הפשוטה שלי, שהיא פשוט θ₁x. אנחנו יכולים, אם אתם רוצים, לחשוב על זה כאילו קבענו את הפרמטר θ₀ להיות שווה ל-0. אז יש לי רק פרמטר אחד, θ₁ ופונקציית העלות שלי דומה לקודמת אלא שעכשיו h של x שווה θ₁x. אז יש לנו רק פרמטר אחד, θ₁ ומטרת האופטימיזציה שלי היא למזער את (J(θ₁. בתמונות מה שזה אומר הוא שאם θ₀ שווה אפס זה תואם לכך שאנחנו בוחרים רק פונקציות השערה שעוברות דרך ראשית הצירים, עוברות דרך הנקודה (0, 0). באמצעות הגדרה פשוטה זו של פונקצית עלות פשוטה בואו ננסה להבין את מושג פונקצית העלות בצורה טובה יותר. יש שתי פונקציות מרכזיות שאותן אנחנו רוצים להבין. הראשונה היא פונקצית ההשערה, והשניה היא פונקצית העלות. אז, שימו לב לפונקציית ההשערה, (h(x. לגבי ערך נתון של θ₁, זו פונקציה של x. במילים אחרות ההשערה היא פונקציה של גודלו של הבית x. לעומת זאת, פונקצית העלות J היא פונקציה של הפרמטר θ₁, שמגדיר את השיפוע של הקו הישר. בואו נשרטט את הפונקציות האלה וננסה להבין את שתיהם טוב יותר. בואו נתחיל עם פונקצית ההשערה. משמאל, נניח שנתונה כאן סדרת האימון שלי עם שלוש נקודות (1, 1), (2, 2), ו (3, 3). בואו נבחר ערך של 1 עבור θ₁, אז כאשר θ₁ שווה 1, וזו הבחירה שלי עבור θ₁, אז פונקצית ההשערה תיראה כמו הקו הישר הזה כאן. ואני מזכיר שכשאני משרטט את פונקצית ההשערה שלי. ציר ה- x, הציר האופקי שלי המסומן בx, מסמן את גודלו של הבית. עכשיו, הצבנו את הערך 1 בθ₁, מה שאני רוצה לעשות הוא לחשב את J של θ₁, כאשר θ₁ שווה 1. אז בואו נחשב את פונקצית העלות לגבי הערך 1. כרגיל, פונקצית העלות שלי מוגדרת כאן, נכון? סכום של ריבועי השגיאה של סדרת האימון. אז זה שווה (θ₁x(i פחות (y(i ואם נפשט את זה יצא לנו אפס בריבוע ואפס בריבוע ואפס בריבוע שזה פשוט שווה לאפס. עכשיו, בפונקצית העלות, כל אחד מהאברים האלה כאן שווה לאפס. כי בסדרת האימון הספציפית שלנו, הדגימות הן (1, 1), (2, 2), (3,3). אם θ₁ שווה 1, אז h של (x(i שווה בדיוק ל-(y(i. תרשו לי לכתוב את זה יותר טוב. בסדר? אז (h(x מינוס y, כל אחד מהאיברים שווה לאפס, ולכן קיבלנו ש-J של 1 שווה לאפס. אז עכשיו אנחנו יודעים ש (J(1 שווה לאפס. בואו נצייר את זה. מה שאני הולך לעשות הוא לצייר מימין את פונקציית העלות J, ושימו לב שפונקצית העלות היא פונקציה של הפרמטר θ₁, כשאני משרטט את פונקצית העלות, הציר האופקי מתויג ב-θ₁. אז יש לי (J(1 שווה 0 אז בואו נסמן את זה בx כאן. עכשיו נסתכל על כמה דוגמאות אחרות. θ₁ יכול לקבל מגוון של ערכים שונים. אז θ₁ יכול להיות ערך שלילי, אפס, ערכים חיוביים. אז מה אם θ₁ שווה 0.5. מה קורה אז? בואו נשרטט את זה. אני אגדיר θ₁ שווה 0.5, ואז ההשערה שלי נראית כך. קו עם שיפוע של 0.5, ועכשיו נחשב את (J(0.5, שהוא 1/2m כפול פונקצית העלות הרגילה. לפי הציור רואים שפונקציית העלות תהיה הסכום של הריבוע של הגובה של הקו הזה ועוד הריבוע של הגובה של הקו הזה ועוד הריבוע של הגובה של הקו הזה, נכון? כי המרחק האנכי הזה הוא פשוט ההפרש בין הערך החזוי, (h(xi, ובין הערך האמיתי. אז הדוגמא הראשונה היא 0.5 מינוס אחת בריבוע. כי ההשערה ניבאה 0.5. והערך האמיתי הוא אחד. בדוגמה השניה נקבל אחד מינוס שתיים בריבוע, כי ההשערה ניבאה אחת, אבל המחיר בפועל היה שתיים. והאחרון, 1.5 פחות שלוש בריבוע. וכל זה חלקי שתיים כפול שלוש. כי m הוא גודל הסדרה, נכון, שיש בה שלוש דוגמאות. אז נפשט את הסוגריים ויוצא 3.5. אז זה 3.5 חלקי שש שזה בערך 0.68. אז עכשיו אנחנו יודעים ש-(J(0.5 הוא כ-0.68. בואו נשרטט את זה. אה סליחה, טעות במתמטיקה, זה בעצם כ-0.58. אז אנחנו נצייר את זה בערך כאן. בסדר? עכשיו, בוא נעשה עוד אחד. אם θ₁ שווה 0, כמה זה (J(0? אם θ₁ שווה אפס, אז (h(x זה הקו הקבוע הזה, על הציר האופקי. אז נחשב את השגיאות. יש לנו (J(0 שווה ל-1 חלקי 2m, כפול אחת בריבוע פלוס שתיים בריבוע פלוס שלוש בריבוע, שזה שישית של ארבע עשרה שזה בערך 2.3. אז נסמן גם את זה. זה כאן, בערך 2.3 וכמובן נוכל להמשיך לעשות את זה עבור עוד ערכים של θ₁. אז θ₁ יכול גם לקבל ערכים שליליים ואם θ₁ הוא שלילי אז h של x יהיה שווה נניח מינוס 0.5 כפול x אז θ₁ הוא מינוס 0.5 וזו השערה עם שיפוע 0.5 שלילי. ואפשר להמשיך ולחשב את השגיאות הללו. אז לפי החישוב עבור 0.5, מתברר שהשגיאה באמת גבוהה. זה יוצא משהו כמו 5.25. וכולי וכולי. לגבי ערכים שונים של θ₁, אפשר לחשב את הדברים האלה, נכון? ומתברר כי כשעוברים על מגוון של ערכים, מקבלים משהו כזה. ועל ידי חישוב של ערכים בטווח, בעצם אפשר להבין לאט לאט מה פירוש הפונקציה (J(θ, והיא נראית כך. לסיכום, עבור כל ערך של θ₁, כל ערך של θ₁ מתאים להשערה שונה, או לקו ישר שונה כאן בגרף השמאלי. ובשביל כל ערך של θ₁, נוכל למצוא ערך שונה של הפונקציה, (J(θ₁. לדוגמא θ₁ = 1, מתאים לישר הזה שעובר דרך הנתונים. בעוד θ₁ = 0.5, הנקודה הזו המוצגת בצבע מגנטה מתאימה לקו הזה, ו-θ₁ = 0 כאן בכחול מתאימה לקו האופקי הזה. כך עבור כל ערך של θ₁ אנחנו מקבלים בסופו של דבר ערך אחר של (J(θ₁ ואפשר להשתמש בזה כדי לשרטט את הגרף מימין. עכשיו אם אתם זוכרים, המטרה שלנו היא אופטימיזציה עבור אלגוריתם הלמידה שלנו, בגללה אנחנו רוצים לבחור את הערך של θ₁ שממזער את (J(θ₁. נכון? זו היתה פונקציית המטרה שלנו בשביל הרגרסיה הליניארית. ובכן, כשמסתכלים על העקום הזה, רואים שהערך שממזער את (J(θ₁ הוא θ₁ = 1. והפלא ופלא, זה אכן מתאים לקו הישר הטוב ביותר שניתן להתאים לנתונים שלנו, כשמגדירים θ₁ = 1, עם סדרת האימון המסוימת הזו, אנחנו באמת מקבלים קו שהולם אותה בצורה מושלמת. וזו הסיבה שמזעור של (J(θ₁ מתאים למציאת קו ישר שמתאים לנתונים. אז לסיכום, בסרטון הזה חקרנו כמה גרפים כדי להבין את פונקצית העלות. לשם כך, השתמשנו באלגוריתם פשוט שבו היה רק פרמטר אחד, θ₁. והגדרנו את הפרמטר θ₀ להיות אפס. בסרטון הבא, נחזור לניסוח המקורי של הבעיה ונסתכל על כמה הדמיות שבהם יש גם θ₀ וגם θ₁. כלומר ללא קביעה של θ₀ להיות אפס. ואני מקווה שזה יתן לכם תחושה אפילו עוד יותר טובה של תפקידה של פונקצית העלות J בפתרון בעיית הרגרסיה הליניארית המקורית.