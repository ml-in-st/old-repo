1
00:00:00,000 --> 00:00:04,100
בסרטון הקודם, נתנו הגדרה מתמטית של פונקצית

2
00:00:04,100 --> 00:00:08,616
עלות. בסרטון הזה, בואו נסתכל על כמה דוגמאות, כדי לקבל אינטואיציה

3
00:00:08,616 --> 00:00:14,466
לגבי מה עושה פונקצית העלות, ולמה אנחנו רוצים להשתמש בה. לתזכורת,

4
00:00:14,466 --> 00:00:19,396
הנה מה שעשינו בפעם שעברה. אנחנו רוצים להתאים קו ישר דרך הנתונים שלנו, אז יצרנו

5
00:00:19,396 --> 00:00:23,958
השערה עם הפרמטרים הללו θ₀ ו-θ₁,

6
00:00:23,958 --> 00:00:28,888
ועל ידי שימוש בערכים שונים של הפרמטרים אנחנו מקבלים קוים ישרים והתאמות

7
00:00:31,323 --> 00:00:33,758
שונות לנתונים, ויש לנו פונקציית עלות,

8
00:00:33,758 --> 00:00:38,554
וזו היתה מטרת האופטימיזציה שלנו. אז בסרטון הזה, כדי שנוכל לדמיין

9
00:00:38,554 --> 00:00:43,293
את j פונקציית העלות יותר טוב בעיני רוחנו, אני אעבוד עם פונקציה השערה פשוטה,

10
00:00:43,293 --> 00:00:48,220
כמו זו המוצגת כאן מימין. אני אשתמש בהשערה הפשוטה שלי,

11
00:00:48,220 --> 00:00:53,275
שהיא פשוט θ₁x. אנחנו יכולים, אם אתם רוצים, לחשוב על זה כאילו קבענו

12
00:00:53,275 --> 00:00:58,721
את הפרמטר θ₀ להיות שווה ל-0. אז יש לי רק פרמטר אחד, θ₁

13
00:00:58,721 --> 00:01:04,372
ופונקציית העלות שלי דומה לקודמת אלא שעכשיו h של x שווה

14
00:01:04,372 --> 00:01:10,309
θ₁x. אז יש לנו רק פרמטר אחד, θ₁

15
00:01:10,309 --> 00:01:16,246
ומטרת האופטימיזציה שלי היא למזער את (J(θ₁. בתמונות מה שזה אומר הוא

16
00:01:16,246 --> 00:01:21,611
שאם θ₀ שווה אפס זה תואם לכך שאנחנו בוחרים רק פונקציות השערה

17
00:01:21,611 --> 00:01:27,176
שעוברות דרך ראשית הצירים, עוברות דרך הנקודה (0, 0). באמצעות

18
00:01:27,176 --> 00:01:33,415
הגדרה פשוטה זו של פונקצית עלות פשוטה בואו ננסה להבין את מושג

19
00:01:33,415 --> 00:01:40,178
פונקצית העלות בצורה טובה יותר. יש שתי פונקציות מרכזיות שאותן אנחנו רוצים להבין.

20
00:01:40,178 --> 00:01:46,432
הראשונה היא פונקצית ההשערה, והשניה היא פונקצית העלות. אז, שימו לב

21
00:01:46,432 --> 00:01:52,068
לפונקציית ההשערה, (h(x. לגבי ערך נתון של θ₁, זו

22
00:01:52,068 --> 00:01:58,168
פונקציה של x. במילים אחרות ההשערה היא פונקציה של גודלו של הבית x.

23
00:01:58,168 --> 00:02:03,959
לעומת זאת, פונקצית העלות J היא פונקציה של הפרמטר θ₁,

24
00:02:03,959 --> 00:02:09,993
שמגדיר את השיפוע של הקו הישר. בואו נשרטט את הפונקציות האלה

25
00:02:09,993 --> 00:02:15,481
וננסה להבין את שתיהם טוב יותר. בואו נתחיל עם פונקצית ההשערה. משמאל,

26
00:02:15,481 --> 00:02:20,283
נניח שנתונה כאן סדרת האימון שלי עם שלוש נקודות (1, 1), (2, 2), ו (3, 3).

27
00:02:20,283 --> 00:02:25,338
בואו נבחר ערך של 1 עבור θ₁, אז כאשר θ₁ שווה 1, וזו הבחירה שלי

28
00:02:25,338 --> 00:02:30,392
עבור θ₁, אז פונקצית ההשערה תיראה כמו הקו הישר הזה כאן.

29
00:02:30,392 --> 00:02:35,234
ואני מזכיר שכשאני משרטט את פונקצית ההשערה שלי. ציר ה- x,

30
00:02:35,234 --> 00:02:40,525
הציר האופקי שלי המסומן בx, מסמן את גודלו של הבית.

31
00:02:40,525 --> 00:02:46,551
עכשיו, הצבנו את הערך 1 בθ₁, מה שאני רוצה לעשות הוא

32
00:02:46,551 --> 00:02:52,430
לחשב את J של θ₁, כאשר θ₁ שווה 1. אז בואו

33
00:02:52,430 --> 00:02:58,781
נחשב את פונקצית העלות לגבי הערך 1. כרגיל,

34
00:02:58,781 --> 00:03:05,761
פונקצית העלות שלי מוגדרת כאן, נכון? סכום של

35
00:03:05,761 --> 00:03:13,840
ריבועי השגיאה של סדרת האימון. אז זה שווה

36
00:03:14,740 --> 00:03:25,066
(θ₁x(i פחות (y(i ואם נפשט את זה יצא לנו

37
00:03:25,066 --> 00:03:31,995
אפס בריבוע ואפס בריבוע ואפס בריבוע שזה פשוט שווה לאפס.

38
00:03:31,995 --> 00:03:39,098
עכשיו, בפונקצית העלות, כל אחד מהאברים האלה כאן שווה לאפס. כי

39
00:03:39,098 --> 00:03:46,288
בסדרת האימון הספציפית שלנו, הדגימות הן (1, 1), (2, 2), (3,3). אם θ₁

40
00:03:46,288 --> 00:03:54,667
שווה 1, אז h של (x(i שווה בדיוק ל-(y(i. תרשו לי לכתוב

41
00:03:54,667 --> 00:04:04,164
את זה יותר טוב. בסדר? אז (h(x מינוס y, כל אחד מהאיברים שווה לאפס,

42
00:04:04,164 --> 00:04:14,821
ולכן קיבלנו ש-J של 1 שווה לאפס. אז עכשיו אנחנו יודעים ש (J(1

43
00:04:14,821 --> 00:04:20,504
שווה לאפס. בואו נצייר את זה. מה שאני הולך לעשות הוא לצייר מימין את פונקציית

44
00:04:20,504 --> 00:04:26,187
העלות J, ושימו לב שפונקצית העלות היא פונקציה של הפרמטר

45
00:04:26,187 --> 00:04:32,017
θ₁, כשאני משרטט את פונקצית העלות, הציר האופקי מתויג

46
00:04:32,017 --> 00:04:38,069
ב-θ₁. אז יש לי (J(1 שווה 0 אז בואו נסמן את זה בx כאן.

47
00:04:38,069 --> 00:04:46,464
עכשיו נסתכל על כמה דוגמאות אחרות. θ₁ יכול לקבל

48
00:04:46,464 --> 00:04:52,470
מגוון של ערכים שונים. אז θ₁ יכול להיות ערך שלילי,

49
00:04:52,470 --> 00:04:58,876
אפס, ערכים חיוביים. אז מה אם θ₁ שווה 0.5. מה קורה אז? בואו

50
00:04:58,876 --> 00:05:05,442
נשרטט את זה. אני אגדיר θ₁ שווה 0.5, ואז

51
00:05:05,442 --> 00:05:11,688
ההשערה שלי נראית כך. קו עם שיפוע של 0.5, ועכשיו

52
00:05:11,688 --> 00:05:17,855
נחשב את (J(0.5, שהוא 1/2m כפול פונקצית העלות הרגילה.

53
00:05:17,855 --> 00:05:23,769
לפי הציור רואים שפונקציית העלות תהיה הסכום של הריבוע של

54
00:05:23,769 --> 00:05:29,609
הגובה של הקו הזה ועוד הריבוע של הגובה של הקו הזה ועוד

55
00:05:29,609 --> 00:05:34,783
הריבוע של הגובה של הקו הזה, נכון? כי המרחק האנכי הזה

56
00:05:34,783 --> 00:05:42,854
הוא פשוט ההפרש בין הערך החזוי, (h(xi, ובין הערך האמיתי.

57
00:05:42,854 --> 00:05:48,772
אז הדוגמא הראשונה היא 0.5 מינוס אחת בריבוע.

58
00:05:49,033 --> 00:05:55,647
כי ההשערה ניבאה 0.5. והערך האמיתי הוא אחד.

59
00:05:55,647 --> 00:06:02,436
בדוגמה השניה נקבל אחד מינוס שתיים בריבוע, כי ההשערה ניבאה

60
00:06:02,436 --> 00:06:09,663
אחת, אבל המחיר בפועל היה שתיים. והאחרון, 1.5 פחות שלוש בריבוע.

61
00:06:09,663 --> 00:06:17,263
וכל זה חלקי שתיים כפול שלוש. כי m הוא

62
00:06:17,263 --> 00:06:24,274
גודל הסדרה, נכון, שיש בה שלוש דוגמאות.

63
00:06:24,274 --> 00:06:33,011
אז נפשט את הסוגריים ויוצא 3.5. אז זה 3.5 חלקי שש שזה בערך

64
00:06:33,011 --> 00:06:41,085
0.68. אז עכשיו אנחנו יודעים ש-(J(0.5 הוא כ-0.68. בואו נשרטט את זה. אה

65
00:06:41,085 --> 00:06:50,308
סליחה, טעות במתמטיקה, זה בעצם כ-0.58. אז אנחנו נצייר את זה בערך

66
00:06:50,308 --> 00:07:00,293
כאן. בסדר? עכשיו, בוא נעשה עוד אחד. אם θ₁ שווה 0, כמה

67
00:07:00,293 --> 00:07:08,975
זה (J(0? אם θ₁ שווה אפס, אז (h(x

68
00:07:08,975 --> 00:07:16,916
זה הקו הקבוע הזה, על הציר האופקי.

69
00:07:16,916 --> 00:07:26,882
אז נחשב את השגיאות. יש לנו (J(0 שווה ל-1

70
00:07:26,882 --> 00:07:34,659
חלקי 2m, כפול אחת בריבוע פלוס שתיים בריבוע פלוס שלוש בריבוע, שזה

71
00:07:34,659 --> 00:07:41,555
שישית של ארבע עשרה שזה בערך 2.3. אז נסמן גם את זה. זה

72
00:07:41,555 --> 00:07:47,622
כאן, בערך 2.3 וכמובן נוכל להמשיך לעשות את זה

73
00:07:47,622 --> 00:07:53,335
עבור עוד ערכים של θ₁. אז θ₁ יכול גם לקבל ערכים

74
00:07:53,335 --> 00:07:59,327
שליליים ואם θ₁ הוא שלילי אז h של x יהיה שווה

75
00:07:59,327 --> 00:08:05,179
נניח מינוס 0.5 כפול x אז θ₁ הוא מינוס 0.5 וזו השערה

76
00:08:05,179 --> 00:08:10,188
עם שיפוע 0.5 שלילי. ואפשר

77
00:08:10,188 --> 00:08:15,694
להמשיך ולחשב את השגיאות הללו. אז לפי החישוב עבור 0.5,

78
00:08:15,694 --> 00:08:21,520
מתברר שהשגיאה באמת גבוהה. זה יוצא משהו כמו 5.25.

79
00:08:21,520 --> 00:08:28,087
וכולי וכולי. לגבי ערכים שונים של θ₁, אפשר לחשב את הדברים האלה, נכון?

80
00:08:28,087 --> 00:08:34,413
ומתברר כי כשעוברים על מגוון של ערכים, מקבלים משהו כזה.

81
00:08:34,413 --> 00:08:40,499
ועל ידי חישוב של ערכים בטווח, בעצם אפשר להבין לאט לאט

82
00:08:40,499 --> 00:08:50,999
מה פירוש הפונקציה (J(θ, והיא נראית כך. לסיכום,

83
00:08:50,999 --> 00:08:57,851
עבור כל ערך של θ₁, כל ערך של θ₁ מתאים

84
00:08:57,851 --> 00:09:04,448
להשערה שונה, או לקו ישר שונה כאן בגרף השמאלי. ובשביל כל ערך

85
00:09:04,448 --> 00:09:11,723
של θ₁, נוכל למצוא ערך שונה של הפונקציה, (J(θ₁.

86
00:09:11,723 --> 00:09:19,354
לדוגמא θ₁ = 1, מתאים לישר הזה

87
00:09:19,354 --> 00:09:27,846
שעובר דרך הנתונים. בעוד θ₁ = 0.5, הנקודה הזו המוצגת בצבע מגנטה

88
00:09:27,846 --> 00:09:35,340
מתאימה לקו הזה, ו-θ₁ = 0 כאן בכחול מתאימה

89
00:09:35,340 --> 00:09:41,527
לקו האופקי הזה. כך עבור כל ערך של θ₁ אנחנו מקבלים בסופו של דבר

90
00:09:41,527 --> 00:09:48,516
ערך אחר של (J(θ₁ ואפשר להשתמש בזה כדי לשרטט

91
00:09:48,516 --> 00:09:54,461
את הגרף מימין. עכשיו אם אתם זוכרים, המטרה שלנו היא אופטימיזציה

92
00:09:54,461 --> 00:10:01,963
עבור אלגוריתם הלמידה שלנו, בגללה אנחנו רוצים לבחור את הערך של θ₁ שממזער את (J(θ₁.

93
00:10:01,963 --> 00:10:08,076
נכון? זו היתה פונקציית המטרה שלנו בשביל הרגרסיה הליניארית. ובכן, כשמסתכלים

94
00:10:08,076 --> 00:10:13,710
על העקום הזה, רואים שהערך שממזער את (J(θ₁ הוא θ₁ = 1.

95
00:10:13,710 --> 00:10:19,132
והפלא ופלא, זה אכן מתאים לקו הישר הטוב ביותר שניתן להתאים

96
00:10:19,132 --> 00:10:24,624
לנתונים שלנו, כשמגדירים θ₁ = 1, עם סדרת האימון

97
00:10:24,624 --> 00:10:30,328
המסוימת הזו, אנחנו באמת מקבלים קו שהולם אותה בצורה מושלמת. וזו הסיבה שמזעור

98
00:10:30,328 --> 00:10:36,447
של (J(θ₁ מתאים למציאת קו ישר שמתאים לנתונים.

99
00:10:36,447 --> 00:10:40,884
אז לסיכום, בסרטון הזה חקרנו כמה גרפים כדי להבין את פונקצית

100
00:10:40,884 --> 00:10:45,259
העלות. לשם כך, השתמשנו באלגוריתם פשוט שבו היה רק

101
00:10:45,259 --> 00:10:50,258
פרמטר אחד, θ₁. והגדרנו את הפרמטר θ₀ להיות אפס. בסרטון הבא,

102
00:10:50,258 --> 00:10:54,445
נחזור לניסוח המקורי של הבעיה ונסתכל על כמה

103
00:10:54,445 --> 00:10:59,570
הדמיות שבהם יש גם θ₀ וגם θ₁. כלומר

104
00:10:59,570 --> 00:11:04,757
ללא קביעה של θ₀ להיות אפס. ואני מקווה שזה יתן לכם תחושה אפילו עוד יותר טובה

105
00:11:04,757 --> 00:11:09,257
של תפקידה של פונקצית העלות J בפתרון בעיית הרגרסיה הליניארית המקורית.